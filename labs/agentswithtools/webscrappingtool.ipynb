{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUserProxy\u001b[0m (to WebScraper):\n",
      "\n",
      "Can you scrape agentops.ai for me?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mWebScraper\u001b[0m (to UserProxy):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_Ick8Si2AKdStchD4OaDowB0v): scrape_page *****\u001b[0m\n",
      "Arguments: \n",
      "{\"url\":\"https://agentops.ai\"}\n",
      "\u001b[32m****************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION scrape_page...\u001b[0m\n",
      "\u001b[33mUserProxy\u001b[0m (to WebScraper):\n",
      "\n",
      "\u001b[33mUserProxy\u001b[0m (to WebScraper):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_Ick8Si2AKdStchD4OaDowB0v) *****\u001b[0m\n",
      "AgentOps\n",
      "Agents Suck\n",
      "Without AgentOps.\n",
      "Industry leading developer platform to test and debug AI agents. \n",
      "We built the tools so you don't have to.\n",
      "Powering thousands of engineers buliding reliable agents\n",
      "Visualize\n",
      "Visually track events such as LLM calls, tools, and multi-agent interactions.\n",
      "Time Travel Debugging\n",
      "Rewind and replay agent runs with point in time precision.\n",
      "Debug and Audit\n",
      "Keep a full data trail of logs, errors, and prompt injection attacks from prototype to production.\n",
      "One SDK. Many integrations.\n",
      "Native integrations with the top agent frameworks\n",
      "Track spending\n",
      "Across multiple agents.\n",
      "Research analyst\n",
      "Total spend $3.00\n",
      "Base Agent\n",
      "Fine-tuned Agent\n",
      "Token Counts\n",
      "Track, save, and monitor every token your agent sees.\n",
      "Cost Tracking\n",
      "Manage and vizualize agent spend with up-to-date price monitoring.\n",
      "Fine-tuning\n",
      "Fine-tune specialized LLMs up to 25x cheaper on saved completions.\n",
      "Pricing\n",
      "Free to get started. Flexibility at scale.\n",
      "Basic \n",
      "$0 per month\n",
      "Free up to 1,000 events\n",
      "Features\n",
      "Agent Agnostic SDK\n",
      "LLM Cost Tracking (400+ LLMs)\n",
      "Replay Analytics\n",
      "Pro starts at\n",
      "$40 per month\n",
      "Up to 10,000 events\n",
      "Everything in Basic plus:\n",
      "Custom Tests\n",
      "Time Travel Debugging\n",
      "Email Support\n",
      "Role-based permissioning\n",
      "LLM Threat Detection\n",
      "Enterprise starts at\n",
      "Custom \n",
      "Going beyond? Let's chat\n",
      "Everything in Pro plus:\n",
      "SLA\n",
      "Slack Connect\n",
      "Custom SSO\n",
      "On-premise deployment\n",
      "Custom data retention policy\n",
      "Self-hosting (AWS, GCP, Azure)\n",
      "SOC-2, HIPAA, NIST AI RMF\n",
      "Need help building agents?\n",
      "We've tested 240+ agents. We know which ones actually work.\n",
      "The future is High Agency. \n",
      "Are you ready to build it?\n",
      "\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mWebScraper\u001b[0m (to UserProxy):\n",
      "\n",
      "Here's the content I scraped from [AgentOps](https://agentops.ai):\n",
      "\n",
      "### AgentOps - Agents Suck Without AgentOps.\n",
      "Industry leading developer platform to test and debug AI agents. We built the tools so you don't have to.\n",
      "\n",
      "### Features:\n",
      "- **Visualize**: Track events such as LLM calls, tools, and multi-agent interactions.\n",
      "- **Time Travel Debugging**: Rewind and replay agent runs with point in time precision.\n",
      "- **Debug and Audit**: Full data trail of logs, errors, and prompt injection attacks from prototype to production.\n",
      "- **One SDK. Many integrations.**: Native integrations with top agent frameworks.\n",
      "- **Track spending**: Across multiple agents.\n",
      "- **Token Counts**: Track, save, and monitor every token your agent sees.\n",
      "- **Cost Tracking**: Manage and visualize agent spend with up-to-date price monitoring.\n",
      "- **Fine-tuning**: Fine-tune specialized LLMs up to 25x cheaper on saved completions.\n",
      "\n",
      "### Pricing:\n",
      "- **Basic**: $0 per month\n",
      "  - Free up to 1,000 events\n",
      "  - Agent Agnostic SDK\n",
      "  - LLM Cost Tracking (400+ LLMs)\n",
      "  - Replay Analytics\n",
      "- **Pro**: Starts at $40 per month\n",
      "  - Up to 10,000 events\n",
      "  - Custom Tests\n",
      "  - Time Travel Debugging\n",
      "  - Email Support\n",
      "  - Role-based permissioning\n",
      "  - LLM Threat Detection\n",
      "- **Enterprise**: Custom pricing\n",
      "  - Everything in Pro plus:\n",
      "  - SLA\n",
      "  - Slack Connect\n",
      "  - Custom SSO\n",
      "  - On-premise deployment\n",
      "  - Custom data retention policy\n",
      "  - Self-hosting (AWS, GCP, Azure)\n",
      "  - SOC-2, HIPAA, NIST AI RMF\n",
      "\n",
      "### Additional Info:\n",
      "- The platform is powered by thousands of engineers building reliable agents.\n",
      "- They provide support for building and testing agents.\n",
      "\n",
      "If you need detailed content or specific elements from the page, feel free to ask!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUserProxy\u001b[0m (to WebScraper):\n",
      "\n",
      "Please continue if not finished, otherwise return 'TERMINATE'.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mWebScraper\u001b[0m (to UserProxy):\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from apify_client import ApifyClient\n",
    "from typing_extensions import Annotated\n",
    "import sys\n",
    "# adding llms to the system path, make sure to configure the file azureopenai in llms folder with end point details\n",
    "sys.path.append('C:\\\\proddev\\\\research\\\\aiagentssamples\\\\llms\\\\')\n",
    "import azureopenai\n",
    "\n",
    "config_list =azureopenai.config_list\n",
    "# signup free toget you get your api key https://apify.com/, change the key to your key\n",
    "apify_api_key = \"demo\"\n",
    "\n",
    "def scrape_page(url: Annotated[str, \"The URL of the web page to scrape\"]) -> Annotated[str, \"Scraped content\"]:\n",
    "    # Initialize the ApifyClient with your API token\n",
    "    client = ApifyClient(token=apify_api_key)\n",
    "\n",
    "    # Prepare the Actor input\n",
    "    run_input = {\n",
    "        \"startUrls\": [{\"url\": url}],\n",
    "        \"useSitemaps\": False,\n",
    "        \"crawlerType\": \"playwright:firefox\",\n",
    "        \"includeUrlGlobs\": [],\n",
    "        \"excludeUrlGlobs\": [],\n",
    "        \"ignoreCanonicalUrl\": False,\n",
    "        \"maxCrawlDepth\": 0,\n",
    "        \"maxCrawlPages\": 1,\n",
    "        \"initialConcurrency\": 0,\n",
    "        \"maxConcurrency\": 200,\n",
    "        \"initialCookies\": [],\n",
    "        \"proxyConfiguration\": {\"useApifyProxy\": True},\n",
    "        \"maxSessionRotations\": 10,\n",
    "        \"maxRequestRetries\": 5,\n",
    "        \"requestTimeoutSecs\": 60,\n",
    "        \"dynamicContentWaitSecs\": 10,\n",
    "        \"maxScrollHeightPixels\": 5000,\n",
    "        \"removeElementsCssSelector\": \"\"\"nav, footer, script, style, noscript, svg,\n",
    "    [role=\\\"alert\\\"],\n",
    "    [role=\\\"banner\\\"],\n",
    "    [role=\\\"dialog\\\"],\n",
    "    [role=\\\"alertdialog\\\"],\n",
    "    [role=\\\"region\\\"][aria-label*=\\\"skip\\\" i],\n",
    "    [aria-modal=\\\"true\\\"]\"\"\",\n",
    "        \"removeCookieWarnings\": True,\n",
    "        \"clickElementsCssSelector\": '[aria-expanded=\"false\"]',\n",
    "        \"htmlTransformer\": \"readableText\",\n",
    "        \"readableTextCharThreshold\": 100,\n",
    "        \"aggressivePrune\": False,\n",
    "        \"debugMode\": True,\n",
    "        \"debugLog\": True,\n",
    "        \"saveHtml\": True,\n",
    "        \"saveMarkdown\": True,\n",
    "        \"saveFiles\": False,\n",
    "        \"saveScreenshots\": False,\n",
    "        \"maxResults\": 9999999,\n",
    "        \"clientSideMinChangePercentage\": 15,\n",
    "        \"renderingTypeDetectionPercentage\": 10,\n",
    "    }\n",
    "\n",
    "    # Run the Actor and wait for it to finish\n",
    "    run = client.actor(\"aYG0l9s7dbB7j3gbS\").call(run_input=run_input)\n",
    "\n",
    "    # Fetch and print Actor results from the run's dataset (if there are any)\n",
    "    text_data = \"\"\n",
    "    for item in client.dataset(run[\"defaultDatasetId\"]).iterate_items():\n",
    "        text_data += item.get(\"text\", \"\") + \"\\n\"\n",
    "\n",
    "    average_token = 0.75\n",
    "    max_tokens = 20000  # slightly less than max to be safe 32k\n",
    "    text_data = text_data[: int(average_token * max_tokens)]\n",
    "    return text_data\n",
    "\n",
    "from autogen import ConversableAgent, register_function\n",
    "\n",
    "# Create web scrapper agent.\n",
    "scraper_agent = ConversableAgent(\n",
    "    \"WebScraper\",\n",
    "    llm_config={\"config_list\": config_list},\n",
    "    system_message=\"You are a web scrapper and you can scrape any web page using the tools provided. \"\n",
    "    \"Returns 'TERMINATE' when the scraping is done.\",\n",
    ")\n",
    "\n",
    "# Create user proxy agent.\n",
    "user_proxy_agent = ConversableAgent(\n",
    "    \"UserProxy\",\n",
    "    llm_config=False,  # No LLM for this agent.\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config=False,  # No code execution for this agent.\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\") is not None and \"terminate\" in x[\"content\"].lower(),\n",
    "    default_auto_reply=\"Please continue if not finished, otherwise return 'TERMINATE'.\",\n",
    ")\n",
    "\n",
    "# Register the function with the agents.\n",
    "register_function(\n",
    "    scrape_page,\n",
    "    caller=scraper_agent,\n",
    "    executor=user_proxy_agent,\n",
    "    name=\"scrape_page\",\n",
    "    description=\"Scrape a web page and return the content.\",\n",
    ")\n",
    "\n",
    "\n",
    "chat_result = user_proxy_agent.initiate_chat(\n",
    "    scraper_agent,\n",
    "    message=\"Can you scrape agentops.ai for me?\",\n",
    "    summary_method=\"reflection_with_llm\",\n",
    "    summary_args={\n",
    "        \"summary_prompt\": \"\"\"Summarize the scraped content and format summary EXACTLY as follows:\n",
    "---\n",
    "*Company name*:\n",
    "`Acme Corp`\n",
    "---\n",
    "*Website*:\n",
    "`acmecorp.com`\n",
    "---\n",
    "*Description*:\n",
    "`Company that does things.`\n",
    "---\n",
    "*Tags*:\n",
    "`Manufacturing. Retail. E-commerce.`\n",
    "---\n",
    "*Takeaways*:\n",
    "`Provides shareholders with value by selling products.`\n",
    "---\n",
    "*Questions*:\n",
    "`What products do they sell? How do they make money? What is their market share?`\n",
    "---\n",
    "\"\"\"\n",
    "    },\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
